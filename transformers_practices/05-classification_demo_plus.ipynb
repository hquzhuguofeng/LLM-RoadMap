{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 7765\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files='./datasets/ChnSentiCorp_htl_all.csv', split=\"train\")\n",
    "dataset = dataset.filter(lambda x: x['review'] is not None)\n",
    "dataset # 原本7766，如果指定了train之后，只加载train部分, 并过滤none的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 6212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 1553\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49207\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a1634baffd40dca75246cc6f8e53e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e4045d28df491b9cd73cc85d3caff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1553 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6212\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1553\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "\n",
    "def process_function(examples):\n",
    "    tokenizered_examples = tokenizer(examples['review'], max_length=128, truncation=True)\n",
    "    tokenizered_examples['labels'] = examples['label']\n",
    "    return tokenizered_examples\n",
    "\n",
    "tokenizer_datasets = dataset.map(process_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "tokenizer_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainset, validset = tokenizer_datasets['train'], tokenizer_datasets['test']\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n",
    "validloader = DataLoader(validset, batch_size=8, shuffle=True, collate_fn=DataCollatorWithPadding(tokenizer=tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 创建优化器和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49207\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at D:/AI/pretrain_model/models--hfl--rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('D:/AI/pretrain_model/models--hfl--rbt3').cuda()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看dataloader数据\n",
    "type(next(iter(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch['labels'].long()).float().sum()\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "\n",
    "def train(epoch, log_steps):\n",
    "    global_step = 0\n",
    "\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if global_step % log_steps == 0:\n",
    "                print(f\"epoch:{ep}, global_step:{global_step}, current_loss:{output.loss.item()}\")\n",
    "\n",
    "            global_step += 1\n",
    "        acc = evalute()\n",
    "        print(f\"epoch:{ep}, acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, global_step:0, current_loss:0.6160242557525635\n",
      "epoch:0, global_step:100, current_loss:0.29684317111968994\n",
      "epoch:0, global_step:200, current_loss:0.6522433161735535\n",
      "epoch:0, global_step:300, current_loss:0.16382309794425964\n",
      "epoch:0, global_step:400, current_loss:0.06924654543399811\n",
      "epoch:0, global_step:500, current_loss:0.04809744283556938\n",
      "epoch:0, global_step:600, current_loss:0.8146895170211792\n",
      "epoch:0, global_step:700, current_loss:0.5705182552337646\n",
      "epoch:1, global_step:800, current_loss:0.08817816525697708\n",
      "epoch:1, global_step:900, current_loss:0.043421510607004166\n",
      "epoch:1, global_step:1000, current_loss:0.2129090130329132\n",
      "epoch:1, global_step:1100, current_loss:0.1853337287902832\n",
      "epoch:1, global_step:1200, current_loss:0.0816674530506134\n",
      "epoch:1, global_step:1300, current_loss:0.06641850620508194\n",
      "epoch:1, global_step:1400, current_loss:0.04982209950685501\n",
      "epoch:1, global_step:1500, current_loss:0.34130963683128357\n",
      "epoch:2, global_step:1600, current_loss:0.24308311939239502\n",
      "epoch:2, global_step:1700, current_loss:0.014950603246688843\n",
      "epoch:2, global_step:1800, current_loss:0.23506201803684235\n",
      "epoch:2, global_step:1900, current_loss:0.008411192335188389\n",
      "epoch:2, global_step:2000, current_loss:0.07372301071882248\n",
      "epoch:2, global_step:2100, current_loss:0.08201272040605545\n",
      "epoch:2, global_step:2200, current_loss:0.018331503495573997\n",
      "epoch:2, global_step:2300, current_loss:0.3224382698535919\n",
      "epoch:2, acc:0.8976175785064697\n"
     ]
    }
   ],
   "source": [
    "train(epoch=3, log_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：我觉得这家酒店不错，饭很好吃！\n",
      "模型预测结果:好评\n"
     ]
    }
   ],
   "source": [
    "sen = \"我觉得这家酒店不错，饭很好吃！\"\n",
    "id2label = {0:'差评',1:'好评'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors='pt')\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim=-1)\n",
    "  \n",
    "    print(f\"输入：{sen}\\n模型预测结果:{id2label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_langchainchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
