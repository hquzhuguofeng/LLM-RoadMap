{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 掩码语言模型训练实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'completion'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.load_from_disk('./data/wiki_cn_filtered')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds['completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenier = AutoTokenizer.from_pretrained('D:/pretrained_model/models--hfl--chinese-macbert-base')\n",
    "\n",
    "def process_function(examples):\n",
    "    return tokenier(examples['completion'], max_length=384, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adea2e620b843c08f85f41eb9c75762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenier_datasets = ds.map(process_function, batched=True, remove_columns=ds.column_names)\n",
    "tokenier_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(tokenier_datasets, batch_size=2, collate_fn=DataCollatorForLanguageModeling(tokenier, mlm=True, mlm_probability=0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(dl))[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[MASK]', '[PAD]', 103, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenier.mask_token, tokenier.pad_token, tokenier.mask_token_id, tokenier.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49207\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at D:/pretrained_model/models--hfl--chinese-macbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained('D:/pretrained_model/models--hfl--chinese-macbert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='./masked_lm',\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 创建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49207\\AppData\\Roaming\\Python\\Python311\\site-packages\\accelerate\\accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenier_datasets,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenier, mlm=True, mlm_probability=0.15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800ed56dd572469c9739ff48dde3ff17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4621, 'grad_norm': 8.768919944763184, 'learning_rate': 4.9e-05, 'epoch': 0.02}\n",
      "{'loss': 1.4938, 'grad_norm': 14.427478790283203, 'learning_rate': 4.8e-05, 'epoch': 0.04}\n",
      "{'loss': 1.4778, 'grad_norm': 8.071401596069336, 'learning_rate': 4.7e-05, 'epoch': 0.06}\n",
      "{'loss': 1.4871, 'grad_norm': 8.666216850280762, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 1.4847, 'grad_norm': 7.39116907119751, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n",
      "{'loss': 1.4882, 'grad_norm': 8.970457077026367, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.12}\n",
      "{'loss': 1.4817, 'grad_norm': 7.982434272766113, 'learning_rate': 4.3e-05, 'epoch': 0.14}\n",
      "{'loss': 1.4788, 'grad_norm': 10.128908157348633, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n",
      "{'loss': 1.4878, 'grad_norm': 8.277610778808594, 'learning_rate': 4.1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.4594, 'grad_norm': 8.80448055267334, 'learning_rate': 4e-05, 'epoch': 0.2}\n",
      "{'loss': 1.5048, 'grad_norm': 8.660632133483887, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.22}\n",
      "{'loss': 1.3989, 'grad_norm': 9.086649894714355, 'learning_rate': 3.8e-05, 'epoch': 0.24}\n",
      "{'loss': 1.4456, 'grad_norm': 9.464247703552246, 'learning_rate': 3.7e-05, 'epoch': 0.26}\n",
      "{'loss': 1.3802, 'grad_norm': 9.403613090515137, 'learning_rate': 3.6e-05, 'epoch': 0.28}\n",
      "{'loss': 1.4736, 'grad_norm': 9.250914573669434, 'learning_rate': 3.5e-05, 'epoch': 0.3}\n",
      "{'loss': 1.4714, 'grad_norm': 7.043384552001953, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n",
      "{'loss': 1.4421, 'grad_norm': 9.864738464355469, 'learning_rate': 3.3e-05, 'epoch': 0.34}\n",
      "{'loss': 1.4588, 'grad_norm': 8.639979362487793, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.36}\n",
      "{'loss': 1.3779, 'grad_norm': 7.0248541831970215, 'learning_rate': 3.1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.3837, 'grad_norm': 7.557977199554443, 'learning_rate': 3e-05, 'epoch': 0.4}\n",
      "{'loss': 1.4233, 'grad_norm': 7.119892120361328, 'learning_rate': 2.9e-05, 'epoch': 0.42}\n",
      "{'loss': 1.4655, 'grad_norm': 7.817800521850586, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.44}\n",
      "{'loss': 1.3859, 'grad_norm': 7.504223823547363, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 1.3568, 'grad_norm': 8.519773483276367, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 1.3893, 'grad_norm': 8.348488807678223, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n",
      "{'loss': 1.3499, 'grad_norm': 8.097551345825195, 'learning_rate': 2.4e-05, 'epoch': 0.52}\n",
      "{'loss': 1.3351, 'grad_norm': 8.496423721313477, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 1.4097, 'grad_norm': 8.065537452697754, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.56}\n",
      "{'loss': 1.3769, 'grad_norm': 7.904720783233643, 'learning_rate': 2.1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.3648, 'grad_norm': 10.238448143005371, 'learning_rate': 2e-05, 'epoch': 0.6}\n",
      "{'loss': 1.3832, 'grad_norm': 8.013914108276367, 'learning_rate': 1.9e-05, 'epoch': 0.62}\n",
      "{'loss': 1.3425, 'grad_norm': 8.805788040161133, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n",
      "{'loss': 1.3578, 'grad_norm': 8.214812278747559, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.66}\n",
      "{'loss': 1.3965, 'grad_norm': 9.191519737243652, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.68}\n",
      "{'loss': 1.3183, 'grad_norm': 9.303555488586426, 'learning_rate': 1.5e-05, 'epoch': 0.7}\n",
      "{'loss': 1.3186, 'grad_norm': 8.785107612609863, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}\n",
      "{'loss': 1.3766, 'grad_norm': 9.707991600036621, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.74}\n",
      "{'loss': 1.386, 'grad_norm': 7.790785789489746, 'learning_rate': 1.2e-05, 'epoch': 0.76}\n",
      "{'loss': 1.4178, 'grad_norm': 9.241283416748047, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.78}\n",
      "{'loss': 1.3759, 'grad_norm': 11.147385597229004, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "{'loss': 1.3259, 'grad_norm': 7.251102924346924, 'learning_rate': 9e-06, 'epoch': 0.82}\n",
      "{'loss': 1.415, 'grad_norm': 8.780313491821289, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.84}\n",
      "{'loss': 1.2103, 'grad_norm': 8.112545013427734, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.86}\n",
      "{'loss': 1.3203, 'grad_norm': 6.853764533996582, 'learning_rate': 6e-06, 'epoch': 0.88}\n",
      "{'loss': 1.3783, 'grad_norm': 11.697437286376953, 'learning_rate': 5e-06, 'epoch': 0.9}\n",
      "{'loss': 1.271, 'grad_norm': 8.666814804077148, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.92}\n",
      "{'loss': 1.2939, 'grad_norm': 7.54922342300415, 'learning_rate': 3e-06, 'epoch': 0.94}\n",
      "{'loss': 1.3949, 'grad_norm': 7.505795001983643, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n",
      "{'loss': 1.3117, 'grad_norm': 7.526434421539307, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.98}\n",
      "{'loss': 1.2955, 'grad_norm': 8.450395584106445, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 548.1729, 'train_samples_per_second': 18.242, 'train_steps_per_second': 4.561, 'train_loss': 1.397713217163086, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=1.397713217163086, metrics={'train_runtime': 548.1729, 'train_samples_per_second': 18.242, 'train_steps_per_second': 4.561, 'train_loss': 1.397713217163086, 'epoch': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('fill-mask', model=model, tokenizer=tokenier, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.21726694703102112,\n",
       "  'token': 3241,\n",
       "  'token_str': '晚',\n",
       "  'sequence': '今 天 和 工 联 院 进 行 了 晚 上 的 会 议 ， 彼 此 交 换 了 信 息 ， 达 成 了 一 致 的 认 识'},\n",
       " {'score': 0.0632537379860878,\n",
       "  'token': 4408,\n",
       "  'token_str': '班',\n",
       "  'sequence': '今 天 和 工 联 院 进 行 了 班 上 的 会 议 ， 彼 此 交 换 了 信 息 ， 达 成 了 一 致 的 认 识'},\n",
       " {'score': 0.05488519370555878,\n",
       "  'token': 809,\n",
       "  'token_str': '以',\n",
       "  'sequence': '今 天 和 工 联 院 进 行 了 以 上 的 会 议 ， 彼 此 交 换 了 信 息 ， 达 成 了 一 致 的 认 识'},\n",
       " {'score': 0.04968508705496788,\n",
       "  'token': 3193,\n",
       "  'token_str': '早',\n",
       "  'sequence': '今 天 和 工 联 院 进 行 了 早 上 的 会 议 ， 彼 此 交 换 了 信 息 ， 达 成 了 一 致 的 认 识'},\n",
       " {'score': 0.03416558727622032,\n",
       "  'token': 1963,\n",
       "  'token_str': '如',\n",
       "  'sequence': '今 天 和 工 联 院 进 行 了 如 上 的 会 议 ， 彼 此 交 换 了 信 息 ， 达 成 了 一 致 的 认 识'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"今天和工联院进行了[MASK]上的会议，彼此交换了信息，达成了一致的认识\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.0623011514544487,\n",
       "   'token': 7028,\n",
       "   'token_str': '重',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 重 [MASK] 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.05762332305312157,\n",
       "   'token': 2031,\n",
       "   'token_str': '娱',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 娱 [MASK] 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.04219214990735054,\n",
       "   'token': 4685,\n",
       "   'token_str': '相',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 相 [MASK] 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.04130121320486069,\n",
       "   'token': 3173,\n",
       "   'token_str': '新',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 新 [MASK] 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.03979349136352539,\n",
       "   'token': 3297,\n",
       "   'token_str': '最',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 最 [MASK] 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'}],\n",
       " [{'score': 0.06800579279661179,\n",
       "   'token': 7481,\n",
       "   'token_str': '面',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 [MASK] 面 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.05980544537305832,\n",
       "   'token': 1068,\n",
       "   'token_str': '关',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 [MASK] 关 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.05268591642379761,\n",
       "   'token': 2141,\n",
       "   'token_str': '实',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 [MASK] 实 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.05142950639128685,\n",
       "   'token': 5317,\n",
       "   'token_str': '络',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 [MASK] 络 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'},\n",
       "  {'score': 0.047297731041908264,\n",
       "   'token': 6206,\n",
       "   'token_str': '要',\n",
       "   'sequence': '[CLS] 下 面 是 一 则 [MASK] 要 新 闻 。 小 编 报 道 ， 近 日 ， 游 戏 产 业 发 展 的 非 常 好 ！ [SEP]'}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"下面是一则[MASK][MASK]新闻。小编报道，近日，游戏产业发展的非常好！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_langchainchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
